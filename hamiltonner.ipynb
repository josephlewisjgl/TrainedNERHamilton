{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport gensim\nimport re\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-27T16:32:54.132996Z","iopub.execute_input":"2022-08-27T16:32:54.133485Z","iopub.status.idle":"2022-08-27T16:32:54.799627Z","shell.execute_reply.started":"2022-08-27T16:32:54.133355Z","shell.execute_reply":"2022-08-27T16:32:54.798470Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/hamilton-lyrics/ham_lyrics.csv', encoding='ISO-8859-1')\ndf.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-08-27T16:32:54.803122Z","iopub.execute_input":"2022-08-27T16:32:54.803482Z","iopub.status.idle":"2022-08-27T16:32:54.844053Z","shell.execute_reply.started":"2022-08-27T16:32:54.803447Z","shell.execute_reply":"2022-08-27T16:32:54.843133Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Hamilton Lyrics - Named Entity Recognition\n\nNamed Entity Recognition (NER) is a branch of natural language processing (NLP) dedicated to extracting named entities from text. This notebook based on the hit musical Hamilton will attempt to extract the names of people from the script.","metadata":{}},{"cell_type":"code","source":"import re \n\n# get script as one single string\nlines = [line for line in df['lines']]","metadata":{"execution":{"iopub.status.busy":"2022-08-27T16:32:54.845555Z","iopub.execute_input":"2022-08-27T16:32:54.846205Z","iopub.status.idle":"2022-08-27T16:32:54.854737Z","shell.execute_reply.started":"2022-08-27T16:32:54.846172Z","shell.execute_reply":"2022-08-27T16:32:54.853774Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### Building a training dataset\nThe training dataset that gets passed to SpaCy needs to contain sentence level extracts with the string indices of where the name begins and ends.","metadata":{}},{"cell_type":"code","source":"# find how names are used in the data \n# get list of sentences for training with some names in\nnames = ['Hamilton', 'Burr', 'Alexander', 'Eliza', 'George', 'Jefferson', 'Schyler', 'Thomas']\nextracts = df[df['lines'].str.contains('|'.join(names))].reset_index()\n\n# select only lines over 80 chars\ntraining = [re.sub('[^A-z]', ' ', line) for line in df['lines'] if len(line)>30]\n\nTRAIN = []\n\n# for each line \nfor line in training:\n    # workout which name is included\n    for name in names:\n        found = re.search(name, line)\n        if found:\n            # strip out the start of the string\n            starts = found.start()\n            end = found.end()\n            \n            TRAIN.append((line, {\"entities\": [(starts, end, \"PER\")]}))\nTRAIN[:2]","metadata":{"execution":{"iopub.status.busy":"2022-08-27T16:32:54.857279Z","iopub.execute_input":"2022-08-27T16:32:54.857646Z","iopub.status.idle":"2022-08-27T16:32:54.902034Z","shell.execute_reply.started":"2022-08-27T16:32:54.857613Z","shell.execute_reply":"2022-08-27T16:32:54.901147Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Testing the pre-trained model\nBefore putting the training data to use a test is done on the pre-trained model:","metadata":{}},{"cell_type":"code","source":"import spacy\nnlp = spacy.load('en_core_web_lg')\nnlp.pipe_names","metadata":{"execution":{"iopub.status.busy":"2022-08-27T16:33:34.914301Z","iopub.execute_input":"2022-08-27T16:33:34.914793Z","iopub.status.idle":"2022-08-27T16:33:41.097490Z","shell.execute_reply.started":"2022-08-27T16:33:34.914747Z","shell.execute_reply":"2022-08-27T16:33:41.096201Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"names_pretrained = []\n\n# 430 names \nfor line in lines:\n    doc = nlp(line)\n    for word in doc.ents:\n        if word.label_ == 'PER':\n            names_pretrained.append(word.text)\n\nprint(set(names_pretrained))\nprint(len(names_pretrained))","metadata":{"execution":{"iopub.status.busy":"2022-08-27T16:33:41.100640Z","iopub.execute_input":"2022-08-27T16:33:41.101103Z","iopub.status.idle":"2022-08-27T16:34:07.881138Z","shell.execute_reply.started":"2022-08-27T16:33:41.101065Z","shell.execute_reply":"2022-08-27T16:34:07.879275Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"NER = nlp.get_pipe('ner')\n\n# only change pipelines that need to change\npipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\nunaffected_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]","metadata":{"execution":{"iopub.status.busy":"2022-08-27T16:34:30.754916Z","iopub.execute_input":"2022-08-27T16:34:30.756324Z","iopub.status.idle":"2022-08-27T16:34:30.763934Z","shell.execute_reply.started":"2022-08-27T16:34:30.756265Z","shell.execute_reply":"2022-08-27T16:34:30.762532Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### Adding custom training and testing a trained model\nUsing the training samples above the new model is updated and tested below","metadata":{}},{"cell_type":"code","source":"import random\nfrom spacy.util import minibatch, compounding\nfrom spacy.training import Example\nfrom pathlib import Path\n\n# TRAINING THE MODEL\nwith nlp.disable_pipes(*unaffected_pipes):\n\n  # Training for 30 iterations\n  for iteration in range(50):\n    losses = {}\n    for batch in spacy.util.minibatch(TRAIN, size=1):\n        for text, annotations in batch:\n            # create Example\n            doc = nlp.make_doc(text)\n            example = Example.from_dict(doc, annotations)\n            # Update the model\n            nlp.update([example], losses=losses, drop=0.3)","metadata":{"execution":{"iopub.status.busy":"2022-08-27T16:34:38.042161Z","iopub.execute_input":"2022-08-27T16:34:38.042540Z","iopub.status.idle":"2022-08-27T16:37:39.026768Z","shell.execute_reply.started":"2022-08-27T16:34:38.042495Z","shell.execute_reply":"2022-08-27T16:37:39.025544Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"names = []\n\n# 430 names \nfor line in lines:\n    doc = nlp(line)\n    for word in doc.ents:\n        if word.label_ == 'PER':\n            names.append(word.text)\n            \nprint(set(names))\nprint(len(names))","metadata":{"execution":{"iopub.status.busy":"2022-08-27T16:38:04.387504Z","iopub.execute_input":"2022-08-27T16:38:04.388583Z","iopub.status.idle":"2022-08-27T16:38:29.908376Z","shell.execute_reply.started":"2022-08-27T16:38:04.388533Z","shell.execute_reply":"2022-08-27T16:38:29.907334Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"results = {}\nfor name in names:\n    try:\n        results[name] += 1\n    except:\n        results[name] = 1\n        ","metadata":{"execution":{"iopub.status.busy":"2022-08-27T17:44:21.298934Z","iopub.execute_input":"2022-08-27T17:44:21.300316Z","iopub.status.idle":"2022-08-27T17:44:21.307531Z","shell.execute_reply.started":"2022-08-27T17:44:21.300257Z","shell.execute_reply":"2022-08-27T17:44:21.306236Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"### Plotting the results\nTo find how the pre-trained model did a bar chart is used","metadata":{}},{"cell_type":"code","source":"import plotly.express as px\n\nresults_df = pd.DataFrame({'Names': results.keys(), 'Count':results.values()}).sort_values('Count', ascending=False)\nbar = px.bar(results_df, x='Names', y='Count', template='seaborn')\nbar.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-27T17:32:59.621167Z","iopub.execute_input":"2022-08-27T17:32:59.621712Z","iopub.status.idle":"2022-08-27T17:32:59.690744Z","shell.execute_reply.started":"2022-08-27T17:32:59.621666Z","shell.execute_reply":"2022-08-27T17:32:59.689919Z"},"trusted":true},"execution_count":22,"outputs":[]}]}